# Phase 1 Complete - Data Pipeline Summary

## âœ… What's Working Now

### 1. **Scraper Jobs** (Auto-Import)
```
Admin Panel â†’ Start Scrape Job
    â†“
Python Scraper Runs
    â†“
Individual CSV Created (e.g., omega_stores_timestamp.csv)
    â†“
Master CSV Merged (master_stores.csv) - deduplicates
    â†“
âœ¨ AUTO-IMPORT TO DATABASE âœ¨
    â†“
Location table updated
    â†“
Public Map Shows New Data Immediately
```

### 2. **Manual CSV Uploads** (Fixed - Now Auto-Imports!)
```
Admin Panel â†’ Upload CSV
    â†“
Validation Runs
    â†“
If VALID:
    â†“
âœ¨ AUTO-IMPORT TO DATABASE âœ¨
    â†“
Location table updated
    â†“
Public Map Shows New Data Immediately
```

### 3. **Public Map (prototype.html)**
- **Data Source:** API â†’ Database (NOT CSV files!)
- **URL:** http://localhost:3001/ or http://localhost:3001/prototype.html
- **Features:**
  - Brand filtering
  - Type filtering (Retailers, Boutiques, Malls)
  - Store name search
  - "Near Me" geolocation
  - Radius search (5/10/25/50 miles)
  - All data is LIVE from database

---

## ğŸ“Š Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA SOURCES                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Scraper Jobs (omega, rolex, etc.)                       â”‚
â”‚  2. Manual CSV Uploads                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                VALIDATION & PROCESSING                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - Python validation                                         â”‚
â”‚  - Field mapping                                             â”‚
â”‚  - Deduplication (by handle or name+address)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DATABASE (Location Table)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - Single source of truth                                    â”‚
â”‚  - 1,452+ locations                                          â”‚
â”‚  - Indexed for fast queries                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PUBLIC API                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GET /api/locations          - List all                      â”‚
â”‚  GET /api/locations/stats    - Statistics                    â”‚
â”‚  GET /api/locations/search   - Search by name/address        â”‚
â”‚  GET /api/locations/nearby   - Radius search                 â”‚
â”‚  GET /api/locations/brands   - List unique brands            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PUBLIC MAP (prototype.html)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - Fetches from API                                          â”‚
â”‚  - Real-time data                                            â”‚
â”‚  - Interactive filters                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ About master_stores.csv

**Purpose:** Backup/archive file that accumulates all scraped data

**When Updated:**
- âœ… After every scraper job completes
- âŒ NOT updated by manual CSV uploads (by design)

**Why It Exists:**
- Historical record of all scraper runs
- Backup in case database needs to be rebuilt
- Can be downloaded via admin panel

**Important:**
- **prototype.html does NOT use this file anymore!**
- It uses the API â†’ Database
- The CSV is just a backup/export

---

## ğŸ”„ How Data Stays In Sync

### Scraped Data:
1. Scraper runs â†’ CSV â†’ master_stores.csv â†’ **Database**
2. Map pulls from **Database**
3. âœ… Always in sync

### Manual Uploads:
1. Upload CSV â†’ Validation â†’ **Database** (if valid)
2. Map pulls from **Database**
3. âœ… Always in sync
4. âš ï¸ Does NOT update master_stores.csv (only scrapers do)

---

## ğŸ§ª How to Test

### Test 1: Manual CSV Upload
1. Go to admin panel: http://localhost:5173/uploads
2. Upload a valid CSV with store locations
3. Wait for validation to complete
4. If valid: Data automatically imports to database
5. Refresh http://localhost:3001/ â†’ New stores appear!

### Test 2: Scraper Job
1. Go to admin panel: http://localhost:5173/scraper
2. Start a scrape job (e.g., Omega)
3. Watch logs for:
   ```
   === DATABASE IMPORT ===
   âœ… Import completed
     â€¢ New locations: X
     â€¢ Updated locations: Y
   ```
4. Refresh map â†’ Scraped stores appear!

### Test 3: API Directly
```bash
# Check total locations
curl "http://localhost:3001/api/locations/stats"

# Search
curl "http://localhost:3001/api/locations/search?q=Paris"

# List with filters
curl "http://localhost:3001/api/locations?country=France&limit=10"
```

---

## ğŸ“ Important Files

### Backend:
- `backend/src/services/location.service.ts` - Database operations & CSV import
- `backend/src/services/scraper.service.ts` - Scraper orchestration (lines 267-293: auto-import)
- `backend/src/services/upload.service.ts` - Manual upload handling (lines 58-78: auto-import)
- `backend/src/routes/location.routes.ts` - Public API endpoints
- `backend/src/controllers/location.controller.ts` - API handlers

### Frontend:
- `prototype.html` - Public map (lines 245-294: API integration)
- `admin-frontend/src/pages/Scraper.tsx` - Scraper management
- `admin-frontend/src/pages/Uploads.tsx` - Manual upload management

### Data:
- `backend/dev.db` - SQLite database (Location table)
- `backend/uploads/master_stores.csv` - Backup CSV (scraper output only)
- `backend/uploads/scraped/` - Individual brand CSVs

---

## âœ… Phase 1 Deliverables

- [x] Location Service with CSV import
- [x] Public API endpoints with filtering
- [x] Auto-import after scraper jobs
- [x] Auto-import after manual uploads (NEW FIX!)
- [x] prototype.html connected to API
- [x] Real-time data pipeline
- [x] Database as single source of truth

---

## ğŸš€ Next: Phase 2

- Migrate to PostgreSQL + PostGIS
- Optimize spatial queries
- Production deployment
- Shopify integration

---

**Date:** November 24, 2025
**Status:** Phase 1 Complete âœ…
